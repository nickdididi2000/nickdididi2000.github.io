[
  {
    "path": "posts/Correlated_data_capstone/",
    "title": "Spatial Analysis Lead Levels",
    "description": "Analyzing lead levels in Minneapolis/Saint Paul area through spatial correlation!",
    "author": [
      {
        "name": "Nicholas Di and Erin Franke",
        "url": {}
      }
    ],
    "date": "2022-05-11",
    "categories": [],
    "contents": "\n\n\n\nIntroduction\nWhen raising a child, parents go through lots of stress to keep their\nchildren safe and healthy. From using car seats to getting children\nvaccinated to working on speech and mobility development and beyond,\nthere is a lot to think about. But one aspect that may be overlooked in\nproviding safe and healthy environment for a child is lead. Lead in\npaint, soil, air, or water is invisible to the naked eye and has no\nsmell (“Prevent Children’s\nExposure to Lead” 2021). However, children can be\nexposed to lead in a variety of manners, including swallowing house dust\nor soil contaminated by lead paint or drinking water delivered through\nlead-based pipes, faucets, and plumbing fixtures. Exposure to this\nhidden element can seriously harm a child’s health, including damage to\nthe child’s brain and nervous system, slowed growth and development, as\nwell as learning, hearing, speech, and behavior problems (“Prevent Children’s\nExposure to Lead” 2021). If exposed to especially high\nlevels of lead, children can face a brain condition known as\nencephalopathy, severe neurological damage, comas, and even death (“Annual Elevated Blood Lead Levels”\n2020). Thus, without a question it is crucial to keep lead\nexposure to a minimum when raising a child.\nIn this project, we analyzed elevated blood lead levels in the\n7 county Twin Cities metropolitan area using public\ndata provided by the Minnesota Department of Health\nover the period of 2015-2019 (Health, n.d.). To protect the privacy of\nindividuals, the smallest granularity we were able to obtain this data\nwas on the census tract level, meaning for each of the 691 census tracts\nin the Twin Cities metropolitan area we obtained information on how many\nchildren were tested and how many of those tests resulted in elevated\nblood lead levels. To have elevated blood lead levels\n(EBLLs) means that a child has a confirmed result at or\nabove 5 micrograms of lead per deciliter of blood (mcg/dL)\n(“Annual Elevated\nBlood Lead Levels” 2020). Children under 6 years of\nage are tested. The Minnesota Department of Health identifies children\nliving in the Minneapolis and Saint Paul city limits as children at a\nhigher risk for lead exposure and recommends these children to receive\nblood lead testing at 1 and 2 years of age. This recommendation is\nwarranted given that in 2019, between 1-2% of children in Minneapolis or\nSt. Paul had EBLLs, which is double the statewide average and higher\nthan any other region of Minnesota (“Annual Elevated Blood Lead Levels”\n2020). Interestingly, the MDH has found children living in\nthe Metro area but not living in the cities of Minneapolis or St. Paul\nare at a lower risk of lead exposure than the Greater Minnesota\n(non-Metro) are. Only about 0.3% of these children have elevated blood\nlead levels whereas about 0.8% of children living in MN outside the\nmetro area have elevated blood lead levels. As a result, to best explore\nthis contrast between Minneapolis-Saint Paul and the suburban region,\nthis project will solely focus on EBLL data from the 7 county Twin\nCities metro area. This region is shown in navy on the road map of\nMinnesota below.\n\n\n\nResearch Goal\nKeeping the health consequences of lead exposure to children in the\nfront of our minds, our research focuses on investigating what is\ncorrelated with a census tract having a noticeably high proportion of\nchildren testing with elevated blood lead levels. We defined a tract to\nbe a “high lead tract” if at least 1% of the tests in the tract resulted\nin elevated blood lead levels (meaning 5+ mcg lead/dL). This left us\nwith 106 “high lead” tracts and 585 “safe” tracts. The location of these\n“high lead” tracts in the Twin Cities metropolitan area can be seen\nbelow in red. It is clear that the majority of them fall in the\nMinneapolis-Saint Paul city limits.\n\n\n\nThe reason why this research question is important is because\nunderstanding what is correlated with tracts having high lead levels can\nhelp the Minnesota Department of Health, organizations, and families\nprotect children from lead exposure. For example, it wouldn’t be\nunreasonable to expect tracts with older homes to have higher lead\nlevels, as these homes are more likely to have been built when science\ndid not know the harms of lead pipes and paint. On March 28, 2022, Saint\nPaul Mayor Melvin Carter announced a $14.5 million American Rescue Plan\ninvestment to remove thousands of lead pipes across the city (n.d.). If home age appears a strong\nindicator of high lead levels, identifying tracts with old homes, high\nlead levels, and lots of young children can alert the city to replace\ntheir pipes first. In our research we also might search for a\nrelationship between testing, income, and lead levels. If we are to find\ncertain income groups getting tested more or less than others holding\nother variables constant, we can shed light on that and advocate for\nresources to get specific tracts the testing they need and deserve given\ntheir exposure.\nTo help us understand what is correlated with a tract being “high\nlead”, we will need more than just the information provided by the MDH\nof tract lead levels. Using the tidycensus (Walker and Herman 2022) package in R, we\ncan access a plethora of information on each census tract including its\nestimated mean age, mean income, population, proportion of family\nhouseholds, home age, and so much more. We begin by exploring the\nrelationship between many of these variables and testing as well as\nEBLLs.\nExploratory Data Analysis\nEstimated Home Age and EBLLs\nOne of the first variables we decided to explore was estimated home\nage. Using the tidycensus package, we were able to access the number of\nresidences in each census tract built prior to 1950, between 1950-1959,\n1960-1969, etc. We made these variables proportions by dividing the\nnumber of homes built in each time period by the total number of homes\nin the census tract. Most revealing was the proportion of homes built\nprior to 1950 - as seen in the map below, the Minneapolis-Saint Paul\ncity limits are largely composed of these older homes while the tracts\non the outskirts of the city have few very homes built before 1950.\n\n\n\nGiven this visualization and our knowledge of history, it is clear\nthat home age likely plays a strong role in lead exposure in children.\nBut it can’t be the only factor. In the map below, we again identify\ntracts with at least 1% of tests registering with elevated blood lead\nlevels. These tracts are colored red and pink, though in the pink\ntracts less than 25% of homes were built before 1950. We see these\npink tracts generally are located outside the MSP city limits in more\nrecently developed suburban areas.\n\n\n\nComparing these pink tracts we have denoted as “high lead” tracts\nthat contain less than 25% of homes built before 1950 to tracts we have\ndenoted as having safe lead levels, there are a few things to notice.\nOur first thought was that perhaps these pink tracts were still\nsignificantly older than the safe lead level tracks and were just built\nlargely in the 1960s and 70s. Lead-based paint and lead-contaminated\ndust are the most common sources of lead poisoning, and paint containing\nlead was not banned in the United States until 1978 (“Common Sources of Lead Poisoning,”\nn.d.). Therefore, any home built prior to 1978 could\ncertainly serve as an exposure threat to children. It ended up that on\naverage 56.1% percent of the homes in the pink tracts were built before\n1979 compared to 54.8% of homes in the safe lead tracts. With such a\nsmall difference, there has to be something else correlated with a\nhigher proportion of tests with EBLLs in particular tracts. Looking into\nother variables, we found the pink high lead tracts have a slightly\nhigher population density at about 2 people/1000 \\(\\text{m}^2\\) than the safe lead tracts at\n1.4 people/1000 \\(\\text{m}^2\\).\nAdditionally, these pink high lead tracts have an estimated median\nincome of $63,431, whereas the safe lead tracts have an estimated median\nincome of almost $87,661. Lead exposure can also come through occupation\n(people exposed to lead through jobs in fields such as auto repair,\nmining, pipe fitting, battery manufacturing, painting, and construction\ncan bring it home on their clothing), soil, pottery, herbal and folk\nremedies, the ingredient tamarind in candy, and cosmetics (“Lead Poisoning” 2022).\nGiven the significant difference in median income between the pink high\nlead tracts and the safe lead tracts, it is possible that residents from\nthe pink high lead tracts live a different lifestyle than residents in\nthe safe lead tracts that causes them to be exposed to lead at a higher\nrate. Exactly how this lead exposure is happening is a mystery that we\ncannot currently solve given the data we have, but the identification of\nthese somewhat unexpected “high lead” tracts is crucial as it can help\ndirect resources and information toward these tracts in order to reduce\nlead exposure.\n\n\n\nWho is getting tested?\nA large factor of obtaining high lead percentages is related to how\noften an area is tested. As more tests are issued, it is more likely we\nwill observe a high lead percentage since the census tract is taking\nprecautions and responding to factors that already cause EBLLs. It is\ninteresting that there is a population within “high lead” census tracts\nof tracts with newer homes that aren’t getting tested at a high rate. We\ndefined a “high rate” of testing to be when the number of tests in the\ntract is less than the estimated number of children who are 0 to 5 age.\nThese specific census tracts are shown in yellow on the map below and\nseem to be located outside of the cities. We are unsure exactly why this\nis, but perhaps it is a result of poor news and communication in terms\nof safely precautions for high lead levels.\n\n\n\nDoing some further investigation using our binary variables\nindicative of high lead and high testing as well as an estimated tract\nhome age variable, we note some interesting patterns. As we noted with\nthe map above, there are several tracts with on average newer homes that\nhave over 1% of tests with EBLLs but are not getting tested at a high\nrate. Again, this may be the result of ignorance or delayed news.\nAdditionally, among the census tracts that have a high testing ratio,\ntracts denoted as “high lead” tend to have a significantly higher\nestimated home age, which is intuitive as older homes tend to have lead\npipes. Furthermore, looking at the relationship between estimated tract\nmedian income and testing, we see higher income census tracts are\ngetting tested less compared to lower income census tracts.\nThis is intuitive as lower income census tracts may be more risk in\nterms of living in older houses and thus face higher lead exposure.\n\n\n\nModeling\nIn the upcoming section, we will be modeling the binary outcome of\nwhether a census tract is considered to be “high lead” or not. As a\nreminder, we denoted a tract as “high lead” if over 1% of tests\ncontained elevated blood lead levels. The majority of these tracts are\nlocated in the Twin Cities.\nLasso\nWe use LASSO logistic regression to distinguish important variables\nin predicting census tracts with high lead concentrations. After tuning\nfor the best penalty, we discovered that income, proportions of homes\nbuilt before 1950, testing ratio (number of tests/child aged 0 to 5),\nnumber of tests total, and median age of the census tract are important\nvariables in modeling the variance of high lead levels. However, it is\ndifficult to account for spatial correlation using LASSO, so we will not\nbe interpreting the output and standard errors. Instead, we will take\nthe important variables LASSO identified and fit a random effect model.\nThe one exception to this is we will drop variable indicating the total\nnumber of tests and soley use testing ratio, as it is better indicative\nof whether the number of tests a tract receives is appropriate for their\npopulation. This random effect model will account for spatial\ncorrelation. Spatial correlation is very important in our study as\ncensus tracts that are close together will share many similar\ncharacteristics in regards to income, community, and more. Leaving this\nunaccounted for will result in correlated residuals.\nMatern Random Effect Models\nEssentially, a Matern random effects model takes into account the\ncorrelation between points via the euclidean distance between\ncoordinates. Our random effect model accounts for spatial correlation by\nincorporating the X and Y coordinates of the centroid, or center, of\neach census tract. We are able to do so by creating a numeric factor\nrepresenting the coordinates of sampled locations. We fit a constant nu\n(smoothness parameter) for easier computational purposes. We use a nu\nvalue of 0.5, which means the Matern correlation is equivalent to\nspatial exponential decay. Because we have the matern correlation\ncoefficient, we do assume isotropic, meaning that the covariance\nfunction depends only on the computational distance.\nWe use this model as it is an alternative way to account for spatial\ncorrelation, by imposing a correlation structure on the random effect so\nthat each census tract are spatially correlated. In absence of the\nrandom effect, neighboring census tracts will have spatially correlated\nresiduals. When two regions are farther away, we expect the correlation\nbetween them to get lower. Rho is a measure of range correlation,\ntherefore a higher value of rho implies more spatial correlation being\ncaptured by the model.\nWe fit two different models, one with our designated important\nvariables from LASSO and another with an interaction between the\nproportion of homes built before 1950 and a categorical income variable.\nThis interaction suggests that income plays a different role among high\nlead levels conditioned on proportion of hold homes. Perhaps if we are\nat a high income level and have high proportion of old homes, we may see\nreduced probability of high lead levels due to the ability to\nrenovate.\n\n\n\nNow that we have our two models, we can evaluate them. We decided to\nuse a threshold of 70% to predict if a census tract is to be considered\nin the high lead category or not. This means that if the logistic\nregression gives us a predicted probability of .70 or higher, we will\nmake a hard prediction that the census area is high lead. We chose a\nthreshold of .70 as it is gives us the best sensitivity. In the context\nof EBLL, a threshold of 0.70 gives us the most accuracy in correctly\ndetermining a census tract with high lead levels.\nThe signs of all coefficients make sense. As income increases, the\nodds ratio decreases by 0.852 for every 1000 dollar increase in median\nincome holding other variables constant. This is in check with our\nunderstanding as the more income a household has, the more likely they\nwill be able to remodel and replace lead pipes. Additionally, the more\nincome a census tract has, the more newer houses we may see. The\nproportion of homes built before 1950 is the most statistically\nsignificant coefficient. As per the first model, a percentage increase\nin a proportion of homes built before 1950 will increase odds ratio of a\ntract being high lead by 1.25 holding other variables constant. Finally,\nthe coefficient on the test ratio variable is also positive, indicating\nan increase in odds of a census tract being high lead as their test\nratio increases. This is intuitive as tracts that are testing more are\nlikely doing so because they face higher exposure.\nOur interaction terms in the second model were all non-significant.\nMeaning, under the model, category of income did not impact high lead\ndifferently despite being conditioned on the proportion of houses built\nbefore 1950. Although all statistically insignificant, income classes\nthat suffered the most from greater houses built before 1950 were the\ncensus tracts with lowest median income.\nWhy does our prediction have 100% accuracy? Spatial random effect\nwill help improve the prediction because it is using neighboring\ninformation to account for that spatial correlation, doing so more in\nthe mean structure and actually change the prediction, conditioned on\nrandom effects and getting more precise and improved conditions, rather\nthan marginal mean prediction. Hence why we have a 100% prediction\naccuracy for both models, because of the random effect that is able to\ncapture variations that are unobservant.\n\n\n\n\n\n\nModeling\nthe percent of children by census tract with EBLLs\nThus far, we have developed a model to predict whether or not a\ncensus tract will have at least 1% of tests return with an indication of\nEBLLs. But its important to acknowledge that not all census tracts that\nwe have denoted as “high lead” have the same proportion of tests\nindicating EBLLs. For the 106 “high lead” tracts, the distribution of\nthe proportion of tests indicating EBLLs is shown below.\n\n\n\nIn order to better understand this distribution and what is\ncorrelated with certain tracts having a higher percentage of tests with\nEBLLs than others, we will build a model for this percentage using\nsolely the 106 “high lead” tracts. Similar to our logistic model\nbuilding process to predict whether or not a tract is “high lead”, we\nwill begin with a LASSO regression model. Variables that remain in the\nmodel after the shrinkage process can be thought of as most important at\nhelping us identify why certain tracts have a higher percentage of tests\nwith EBLLs than others.\nUsing 10-fold cross validation on our 106 census tracts, the LASSO\nmodeling process identified tract population, the proportion of homes\nbuilt between 1950 and 1969, the proportion of homes built before 1950,\nand the estimated mean receipt of supplemental security income (SSI) for\nhouseholds with children under 18 as the most important predictors of\npercentage of tests with EBLLs. Interestingly, population and amount of\nSSI both showed a negative relationship with percentage of tests with\nEBLLs, meaning more highly populated tracts tend to have a lower\nproportion of tests with EBLLs holding other variables constant.\nAdditionally, tracts receiving more SSI per household tend to have a\nlower proportion of tests with EBLLs holding other variables constant.\nThese relationships are shown in the plots below.\n\n\n\nThe reasoning for this phenomena could be that such higher populated\nand impoverished tracts are viewed “higher risk” for lead exposure and\nhave received greater resources to prevent it thus far.\nNow that we have our model, we can evaluate it. The model appears\nsolid with a RMSE of about 1.5%, meaning on average our prediction of a\ntract’s proportion of tests with EBLLs was either too high or too low by\nabout 1.5%. While this is amount of error is relatively small, our model\nmust also have residuals that do not have spatial autocorrelation. As we\nhave discussed, spatial autocorrelation means residuals in one census\ntract are related to the residuals in the census tracts around it, which\nis problematic because we violate the assumption of independence of\nresiduals and jeopardize the validity of hypothesis tests. We can test\nfor spatial autocorrelation with something called the Moran’s I test. In\norder to run the Moran’s I test, we must decide in what way we want to\ndefine census tracts as “close”. In other words, we must define a\nneighborhood structure. There are many options when\ndefining a neighborhood structure. We can define tracts as neighbors if\nthey touch at all, even just at one point such as a corner. This is\ncalled the Queen neighborhood structure. Another option is the Rook\nneighborhood structure, which defines tracts as neighbors if they share\nan edge (more than just a corner). Neighbors can also be defined using\ndistance. The KNN method calculates the distance between the centers (or\ncentroids) of each census tract, and then defines a neighborhood based\non K nearest tracts, distanced based on the centers (Heggeseth\n2022). Because we are only looking at census tracts with high\nlead levels, some tracts do not touch and thus we will use the KNN\nstructure with 4 neighbors. 4 neighbors gives a nice balance between not\nhaving too many neighbors (which makes census tracts almost always\ncorrelated) and not having too few neighbors, making it harder to pick\nup on spatial correlation. The KNN(4) structure is shown below.\n\n\n\n\n\n\nUsing the Moran’s I test with the KNN(4) structure shown above, there\nis very strong evidence to reject our null hypothesis of no spatial\ncorrelation between neighboring tracts. We thus conclude that census\ntracts closer together tend to have similar percentages of tests with\nEBLLs than census tracts further apart. Given this, we will need to use\na model that accounts for this spatial autocorrelation. Two models that\ncan potentially accomplish this are the simultaneous\nautoregressive model (SAR) and the conditional\nautoregressive model (CAR). These models are fit in a similar\nway to an ordinary least squares model as we predict percent of tests\nwith EBLLs using our selected variables, however, we add a component to\nthe model that allows us to use surrounding neighborhood values at\nvarying weights to estimate percentage of tests with EBLLs for each\ntract. After fitting both a CAR and SAR model using the four variables\nselected by LASSO and the KNN(4) neighborhood structure, we compared\nthem using BIC and the Moran’s I test. From the Moran’s I test we\nlearned the SAR model yielded strong evidence in support of independent\nresiduals. This evidence was significantly weaker for the CAR model,\nimplying remaining spatial autocorrelation in the residuals. The BIC (a\ncriterion used for model selection) was also superior for the SAR model\nin comparison to the CAR model, and thus we decided to proceed with the\nSAR structure. While we tested multiple other SAR models with different\ncombinations of explanatory variables, the model with the four variables\nselected by LASS0 proved our best model with the lowest average\nprediction error (about 1.4%).\n\n\n\nWhile the average predictor error of our model is relatively small at\n1.4%, one obvious downfall of this model is that it did not predict any\ncensus tract to have a percent of tests with EBLLs above 5.6%, as seen\nbelow. In reality - as shown in the dotplot earlier in this modeling\nsection - seven tracts had a percent of tests with EBLLs over 6% and two\ntracts had levels over 10%. Thus, our model does not quite capture as\nlarge of a distribution in tract percentages as well as we might have\nliked.\n\n\n\nDespite this, our model does indeed do a good job of not\nsystematically over or under-predicting particular areas of the Twin\nCities metropolitan area. We see that tracts both inside and outside\ncity limits have a mix of positive and negative residuals and there are\nseveral areas where percent of tests with EBLLs are over predicted in\none tract and under predicted in its neighboring tract. Given the strong\nevidence that spatial autocorrelation was accounted for from the Moran’s\nI test, this is not surprising.\n\n\n\nThe biggest takeaway from our model is what we can learn about lead\nexposure patterns using it. Takeaways are generally similar to the LASSO\nregression model we fit, but we now have more certainty in our\ncoefficient estimates and their significance given we are not breaking\nthe assumption of independent residuals. The two significant\ncoefficients on the \\(\\alpha=0.05\\)\nlevel in our model are tract population and the proportion of homes\nbuilt from 1950 to 1969 in each tract. With regard to population, we\nestimate for every additional 1000 people residing in a tract that the\nproportion of tests with EBLLs falls on average 0.4%, holding other\nvariables constant. Given that census tracts are intended to have\nsimilar populations (ideally ~4000 people), this might not seem\npractically significant at first. However, the 106 “high lead” tracts\nhave populations ranging from about 2,000 to over 10,000 people per\ntract, with the majority falling in the 3000 to 6000 range. Thus,\ncomparing a 6,000 resident to 3,000 resident tract, we’d expect the\n6,000 resident tract to have a percent of tests with EBLLs about 1.2%\nlower than that of the 3,000 resident tract, which is a considerable\ndifference. When looking at our second significant variable, we learn\nthat with every 10% increase in the proportion of homes built between\n1950 and 1969 we can expect the percent of tests with EBLLs to decrease\nabout 0.4%, holding other variables constant. This relationship is shown\nin the graph below on the left and is rather interesting when contrasted\nto the graph on the right, which displays proportion of homes built\nbefore 1950 versus percent of tests with EBLLs for “high lead” tracts.\nThe key takeaway here is that as tracts tend to have more homes built\nbetween 1950-1969, their percent of tests with EBLLs tends to\nfall, while as tracts tend to have more homes built prior to\n1950 their percent of tests with EBLLs tends to rise.\nGiven that lead paint was not banned in the United States until 1978,\nthis contrasting relationship is surprising and implies lead paint is\nnot the sole factor causing tracts to have a high percent of tests with\nEBLLs.\n\n\n\nTo learn a little more about what might be happening, we created the\nfollowing graph which shows the remaining home age distribution for high\nlead tracts based on the proportion of homes built from 1950-1969. We\nsee that tracts with very few homes (less than 20%) built from 1950-1969\nare composed on average by over 50% of homes built before 1950. These\ntracts also have the smallest proportion of homes built from 1970-1989.\nAs the proportion of home built 1950-1969 increases, the proportion of\nhomes built before 1950 in the tract decreases and the proportion of\nhomes built 1970-1989 increases. This implies overall higher average\nhome age and helps to explain why we see that relationship we see in our\nmodel.\n\n\n\nThe SSI and proportion of homes built before 1950 variables are both\ninsignificant in this model, though have coefficient directions that\nmake intuitive sense given what we have discussed thus far. Holding\nother variables constant, as the proportion of homes in a tract built\nprior to 1950 increases, the percent of tests with EBLLs in that tract\nincreases. Additionally, as discussed when interpreting the LASSO model,\ntracts receiving more SSI tend to have a lower percentage of tests with\nEBLLs holding other variables constant.\nLimitations\nOne of the main limitations in our analysis was data. While we are\nincredibly thankful to have access to public lead data and demographics\non the census tract level, we had been hoping to complete a\nspatial-temporal analysis looking at the percent of tests with EBLLs in\neach tract each year dating back to the early 2000s. Unfortunately, the\nMinnesota Department of Health did not have this data on hand. An\nadditional goal of our was to look at building-specific data available\nthrough ArcGIS on lead piping for the St. Paul Regional Water Services\n(SPRWS) area and incorporate it into our analysis. However, we ran out\nof time to learn how to web scrape this and so this will be a task for\nthe near future. One other limitation related to the data for this\nproject is that many of the variables we used are estimates. For\nexample, mean tract age is estimated from ACS and census data. Home\nvalues come from government valuations which is done for tax purposes.\nThe fact that there is likely a fair amount of error in these estimates\nshould be taken into account when interpreting model coefficients. Also\nrelated to the topic of modeling is that fact that no neighborhood\nstructure we choose is going to be perfect. For example, we chose to use\nthe KNN(4) neighborhood structure for our models, which defines four\nneighbors for every tract using distances between tract centroids.\nHowever, it is possible that tracts could be similar in other ways.\nTracts close in distance could be incredibly different due to a highway\nrunning between them, while tracts further apart but both bordering the\nriver could actually be more similar.\nFurthermore, our models will not be the best to predict new data\noutside of our dataset. If we have a new census tract added, it will be\ndifficult to account for the spatial correlation. The new observation\nmay be farther away in distance that it will become independent and we\nwill not gain the extra predictive ability. However, we can use the\ndistributions from the matern random effect models to attempt in making\na prediction for a new area. Unfortunately, we are not able to explain\neverything.\nConclusions\nThroughout our research report, we focused on what seems to be\ncorrelated to high lead levels. We anlyzed data from the\n7-county Twin Cities metropolitan area using public\ndata provided by the Minnesota Department of Health\nover the period of 2015-2019 (Health, n.d.). We fit LASSO models to\npick out “important” variables and utilize different spatial correlation\nregressions to obtain accurate standard errors on the coefficients.\nOverall, the age of homes in the tract and median income of census\ntracts seem to be the most important factors when looking at the\nvariation in high lead levels. This is intuitive as old houses,\nmentioned earlier, tend to have older pipes, more dust, paint chips, all\nof which have a causal effect leading to high lead levels. Among houses\nwith high lead levels, as tract population increases and proportions of\nhomes built between 1950-1969 increases we see that the percent of tests\nreturning EBLLs decreases holding other variables constant.\nFurthermore among census tracts with high lead exposure, there is a\nspecific subgroup of tracts that do not test often (test less than once\nper child) and have a new home age. This is potentially dangerous as\nfamilies living in these census tracts may go on about their routine\nthinking living in a newer household is safe when in reality there may\nbe other factors that contribute to high lead exposure. This is\nespecially concerning as testing rates tend to be lower and the percent\nof tests with EBLLs are higher in these census tracts. For future\nresearch, it will be worthwhile to investigate which census tracts are\ngetting tested more often than others and look into other observable\nfactors that may capture the culture within a census tract with regards\nto lead levels.\nAcknowledgements\nWe thank the Minnesota Department of Health and creators of the\ntidycensus package for providing publicly available data that made our\nwork possible. We also give a big thank you to our professor Brianna\nHeggeseth for teaching us the mapping and modeling techniques used in\nthis analysis, as well as for providing support and resources throughout\nthis project.\nReferences\n\n\n\nn.d. Saint Paul Minnesota. https://www.stpaul.gov/news/saint-paul-announces-145-million-investment-replace-lead-pipes.\n\n\n“Annual Elevated Blood Lead Levels.” 2020. Childhood\nLead Exposure: Annual Blood Lead Levels - MN Data. https://data.web.health.state.mn.us/lead_annual_level.\n\n\n“Common Sources of Lead Poisoning.” n.d. Washington\nState Department of Health. https://doh.wa.gov/you-and-your-family/healthy-home/home-contaminants/lead/common-sources-lead-poisoning.\n\n\nHealth, Minnesota Department of. n.d. Childhood Lead Exposure Map:\nMNPH Data Access - MN Dept. Of Health. https://mndatamaps.web.health.state.mn.us/interactive/leadtract.html.\n\n\nHeggeseth, Brianna. 2022. “Correlated Data Notes.”\nBrianna C. Heggeseth. https://bcheggeseth.github.io/CorrelatedData/index.html.\n\n\n“Lead Poisoning.” 2022. Mayo Clinic. Mayo\nFoundation for Medical Education; Research. https://www.mayoclinic.org/diseases-conditions/lead-poisoning/symptoms-causes/syc-20354717.\n\n\n“Prevent Children’s Exposure to Lead.” 2021. Centers\nfor Disease Control and Prevention. Centers for Disease Control;\nPrevention. https://www.cdc.gov/nceh/features/leadpoisoning/index.html.\n\n\nWalker, Kyle, and Matt Herman. 2022. Tidycensus: Load US Census\nBoundary and Attribute Data as ’Tidyverse’ and ’Sf’-Ready Data\nFrames. https://walker-data.com/tidycensus/.\n\n\n\n\n",
    "preview": "https://assets.nrdc.org/sites/default/files/styles/full_content--retina/public/media-uploads/breakingnews_newarkwater_lawsuit_12716367_1076318232400357_1222393660715498598_o_main.jpg?itok=33uB_PJ0",
    "last_modified": "2022-05-23T15:37:11-07:00",
    "input_file": {}
  },
  {
    "path": "posts/S&P_Bayes_Project/",
    "title": "Bayes Finance Project",
    "description": "Using Bayes Methods to predict future earnings!",
    "author": [
      {
        "name": "Nicholas Di, Nolan Meyer, and Duc Ngo",
        "url": {}
      }
    ],
    "date": "2021-12-11",
    "categories": [],
    "contents": "\nProject\nWelcome to our STAT 454: Bayesian Statistics capstone project. All of\nus group members have an interest in and connections to the financial\nworld, whether that be through our majors or internships, which led us\ntoward this topic. Financial information, like stock market prices, are\nknown to be notoriously hard to predict. We wanted to take a Bayesian\napproach to try and tackle a similar situation: predicting the future\nearnings of S&P 500 companies. In this project we seek to model\nfuture earnings using other financial information about a company, like\nprevious earnings and sales. We explore a few Bayesian hierarchical\nmodels, as well as a SARIMA model using the bayesforcast package to try\nand identify one that can provide insight and better predictions for\nfuture company’s earnings.\nProject\nLink\n\n\n\n",
    "preview": "https://wealthface.com/blog/wp-content/uploads/2021/05/SP500.jpg",
    "last_modified": "2022-05-23T15:08:10-07:00",
    "input_file": {}
  },
  {
    "path": "posts/YouTube_Viz/",
    "title": "YouTube Shiny App",
    "description": "Interactive visualization for youtube viewing data!",
    "author": [],
    "date": "2021-07-01",
    "categories": [],
    "contents": "\n\n\nlibrary(shiny)\nlibrary(tidyverse)\ndata <- read.csv(\"~/Documents/Intro To Data Science/USvideos.txt\")\ndata_cleaned<- data %>%\n  filter(category_id %in% c(\"1\", \"2\", \"10\", \"15\", \"17\", \"19\", \"22\", \"23\", \"24\", \"26\", \"27\", \"28\")) %>%\n  mutate(time_string = toString(publish_time)) %>%\n  mutate(day = substr(time_string, 9, 10)) %>%\n  mutate(likes = as.numeric(likes, na.rm = TRUE)) %>%\n  mutate(dislikes = as.numeric(dislikes, na.rm = TRUE))%>%\n  mutate(like_dislike_ratio = likes / (dislikes + 1))%>%\n  select(title, category_id, tags, views, likes, comment_count, dislikes, like_dislike_ratio)\n\ndata_cleaned <- data_cleaned %>%\n  mutate(category = ifelse(category_id == \"1\", \"Autos & Vehicles\", ifelse(category_id == \"2\", \"Music\", ifelse(category_id == \"10\", \"Comedy\", \n                                                                                                              ifelse(category_id == \"15\", \"Science & Technology\", ifelse(category_id == \"17\", \"Science & Technology\", \n                                                                                                                                                                         ifelse(category_id == \"17\", \"Movies\", ifelse(category_id == \"19\", \"Action/Adventure\", ifelse(category_id == \"22\", \"Documentary\",\n                                                                                                                                                                                                                                                                      ifelse(category_id == \"23\", \"Drama\", ifelse(category_id == \"24\", \"Family\", ifelse(category_id == \"26\", \"Horror\", \n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ifelse(category_id == \"27\", \"Sci-Fi/Fantasy\", \"Thriller\")))))))))))))\ngraphdata <- data_cleaned %>%\n  mutate(category_id_c = as.character(category)) %>% \n  group_by(category_id_c) %>% \n  mutate(views = as.numeric(views, na.rm = TRUE)) %>%\n  mutate(comment_count = as.numeric(comment_count, na.rm = TRUE)) %>%\n  summarise(totallikes = sum(likes, na.rm = TRUE), totaldislikes = sum(dislikes, na.rm = TRUE), \n            totalviews = sum(views, na.rm = TRUE), totalcomment = sum(comment_count, na.rm = TRUE),\n            totalvideos = n(), likes_per_video = totallikes/totalvideos, \n            dislikes_per_video = totaldislikes/ totalvideos, views_per_video = totalviews/totalvideos,\n            comment_count_per_video = totalcomment/totalvideos, like_dislike_ratio_per_video = mean(like_dislike_ratio, na.rm = TRUE))\n\nui <- fluidPage(\n  \n  title = \"Youtube Recommendation\",\n  \n  sidebarLayout(\n    sidebarPanel(\n      conditionalPanel(\n        'input.dataset === \"Users Manual\"',\n        helpText(\"Here is the user's manual\")\n      ),\n      conditionalPanel(\n        'input.dataset === \"Likes\"',\n        selectInput(\"category1\",\n                    \"Category\",\n                    choices = list(\"Autos & Vehicles\" = \"1\", \"Music\" = \"2\", \"Comedy\" = \"10\", \"Science & Technology\" = \"15\", \"Movies\" = \"17\", \"Action/Adventure\" = \"19\", \n                                   \"Documentary\" = \"22\", \"Drama\" = \"23\", \"Family\" = \"24\", \"Horror\" = \"26\", \"Sci-Fi/Fantasy\" = \"27\", \"Thriller\" = \"28\")),\n        checkboxGroupInput(\"show_vars1\",\"Columns to show:\", \n                           list(\"Title\" = \"title\", \"Views\" = \"views\", \"Likes\" = \"likes\", \n                                \"Comment Count\" = \"comment_count\", \"Dislikes\" = \"dislikes\", \"Like Dislike Ratio\" = \"like_dislike_ratio\"), \n                           selected = list(\"title\", \"likes\"))\n      ),\n      conditionalPanel(\n        'input.dataset === \"Dislikes\"',\n        selectInput(\"category2\",\n                    \"Category\",\n                    choices = list(\"Autos & Vehicles\" = \"1\", \"Music\" = \"2\", \"Comedy\" = \"10\", \"Science & Technology\" = \"15\", \"Movies\" = \"17\", \"Action/Adventure\" = \"19\", \n                                   \"Documentary\" = \"22\", \"Drama\" = \"23\", \"Family\" = \"24\", \"Horror\" = \"26\", \"Sci-Fi/Fantasy\" = \"27\", \"Thriller\" = \"28\")),\n        checkboxGroupInput(\"show_vars2\",\"Columns to show:\", \n                          list(\"Title\" = \"title\", \"Views\" = \"views\", \"Likes\" = \"likes\", \n                               \"Comment Count\" = \"comment_count\", \"Dislikes\" = \"dislikes\", \"Like Dislike Ratio\" = \"like_dislike_ratio\"), \n                          selected = list(\"title\", \"dislikes\"))\n      ),\n      conditionalPanel(\n        'input.dataset === \"Comment Count\"',\n        selectInput(\"category3\",\n                    \"Category\",\n                    choices = list(\"Autos & Vehicles\" = \"1\", \"Music\" = \"2\", \"Comedy\" = \"10\", \"Science & Technology\" = \"15\", \"Movies\" = \"17\", \"Action/Adventure\" = \"19\", \n                                   \"Documentary\" = \"22\", \"Drama\" = \"23\", \"Family\" = \"24\", \"Horror\" = \"26\", \"Sci-Fi/Fantasy\" = \"27\", \"Thriller\" = \"28\")),\n        checkboxGroupInput(\"show_vars3\",\"Columns to show:\", \n                           list(\"Title\" = \"title\", \"Views\" = \"views\", \"Likes\" = \"likes\", \n                                \"Comment Count\" = \"comment_count\", \"Dislikes\" = \"dislikes\", \"Like Dislike Ratio\" = \"like_dislike_ratio\"), \n                           selected = list(\"title\", \"comment_count\"))\n      ),\n      conditionalPanel(\n        'input.dataset === \"Views\"',\n        selectInput(\"category4\",\n                    \"Category\",\n                    choices = list(\"Autos & Vehicles\" = \"1\", \"Music\" = \"2\", \"Comedy\" = \"10\", \"Science & Technology\" = \"15\", \"Movies\" = \"17\", \"Action/Adventure\" = \"19\", \n                                   \"Documentary\" = \"22\", \"Drama\" = \"23\", \"Family\" = \"24\", \"Horror\" = \"26\", \"Sci-Fi/Fantasy\" = \"27\", \"Thriller\" = \"28\")),\n        checkboxGroupInput(\"show_vars4\",\"Columns to show:\", \n                           list(\"Title\" = \"title\", \"Views\" = \"views\", \"Likes\" = \"likes\", \n                                \"Comment Count\" = \"comment_count\", \"Dislikes\" = \"dislikes\", \"Like Dislike Ratio\" = \"like_dislike_ratio\"), \n                           selected = list(\"title\", \"views\"))\n      ),\n      conditionalPanel(\n        'input.dataset === \"Like Dislike Ratio\"',\n        selectInput(\"category5\",\n                    \"Category\",\n                    choices = list(\"Autos & Vehicles\" = \"1\", \"Music\" = \"2\", \"Comedy\" = \"10\", \"Science & Technology\" = \"15\", \"Movies\" = \"17\", \"Action/Adventure\" = \"19\", \n                                   \"Documentary\" = \"22\", \"Drama\" = \"23\", \"Family\" = \"24\", \"Horror\" = \"26\", \"Sci-Fi/Fantasy\" = \"27\", \"Thriller\" = \"28\")),\n        checkboxGroupInput(\"show_vars5\",\"Columns to show:\", \n                           list(\"Title\" = \"title\", \"Views\" = \"views\", \"Likes\" = \"likes\", \n                                \"Comment Count\" = \"comment_count\", \"Dislikes\" = \"dislikes\", \"Like Dislike Ratio\" = \"like_dislike_ratio\"), \n                           selected = list(\"title\", \"like_dislike_ratio\"))\n      ),\n      conditionalPanel(\n        'input.dataset === \"Ranking Plot\"',\n        selectInput(\"Vars\",\n                    \"Ranking Categories of Video according to:\",\n                    choices = list(\"Views Per Video\" = \"views\", \"Likes Per Video\" = \"likes\",\n                                   \"Comment Count Per Video\" = \"comment_count\", \"Dislikes Per Video\" = \"dislikes\", \"Average Like Dislike Ratio\" = \"like_dislike_ratio\"))\n      ),\n      \n      conditionalPanel(\n        'input.dataset === \"Distribution of Likes by Categories\"',\n        checkboxGroupInput(\"Categoreis\",\"Categories to be included in the Visulization\",\n                           list(\"Autos & Vehicles\" = \"Autos & Vehicles\", \"Music\" = \"Music\", \"Comedy\" = \"Comedy\", \"Science & Technology\" = \"Science & Technology\", \"Movies\" = \"Movies\", \"Action/Adventure\" = \"Action/Adventure\",\n                                \"Documentary\" = \"Documentary\", \"Drama\" = \"Drama\", \"Family\" = \"Family\", \"Horror\" = \"Horror\", \"Sci-Fi/Fantasy\" = \"Sci-Fi/Fantasy\", \"Thriller\" = \"Thriller\"),\n                           selected = (\"Autos & Vehicles\")\n        )\n      )\n    ),\n    \n    mainPanel(\n      tabsetPanel(\n        id = 'dataset',\n        tabPanel(\"Users Manual\", tags$h2(\"User's Manual\"), htmlOutput(\"manual\")),\n        tabPanel(\"Likes\", DT::dataTableOutput(\"mytable_likes\")),\n        tabPanel(\"Dislikes\", DT::dataTableOutput(\"mytable_dislikes\")),\n        tabPanel(\"Comment Count\", DT::dataTableOutput(\"mytable_comment_count\")),\n        tabPanel(\"Views\", DT::dataTableOutput(\"mytable_views\")),\n        tabPanel(\"Like Dislike Ratio\", DT::dataTableOutput(\"mytable_like_dislike_ratio\")),\n        tabPanel(\"Ranking Plot\", plotOutput(outputId = \"Rankplot\")),\n        tabPanel(\"Distribution of Likes by Categories\", plotOutput(outputId = \"Boxplot\"))\n        \n      )\n    )\n  )\n)\n\n\n\nserver <- function(input, output) {\n    \n    output$mytable_likes <- DT::renderDataTable({\n      data_cleaned %>%\n        mutate(likes = as.numeric(likes)) %>%\n        filter(category_id == input$category1) %>%\n        arrange(desc(likes)) %>%\n        select(input$show_vars1)\n    })\n    \n    output$mytable_dislikes <- DT::renderDataTable({\n      data_cleaned %>%\n        mutate(dislikes = as.numeric(dislikes)) %>%\n        filter(category_id == input$category2) %>%\n        arrange(dislikes) %>%\n        select(input$show_vars2)\n    })\n    \n    output$mytable_comment_count <- DT::renderDataTable({\n      data_cleaned %>%\n        mutate(comment_count = as.numeric(comment_count)) %>%\n        filter(category_id == input$category3) %>%\n        arrange(desc(comment_count)) %>%\n        select(input$show_vars3)\n    })\n    \n    output$mytable_views <- DT::renderDataTable({\n      data_cleaned %>%\n        mutate(views = as.numeric(views)) %>%\n        filter(category_id == input$category4) %>%\n        arrange(desc(views)) %>%\n        select(input$show_vars4)\n    })\n    \n    output$mytable_like_dislike_ratio <- DT::renderDataTable({\n      data_cleaned %>%\n        mutate(like_dislike_ratio = as.numeric(like_dislike_ratio))%>%\n        filter(category_id == input$category5)%>%\n        arrange(desc(like_dislike_ratio)) %>%\n        select(input$show_vars5)\n    })\n    \n    output$manual <- renderText({\n      paste(\n        \"<p>Welcome to our shiny app! This is a fairly self-explanatory app. First off, start off my selecting the categories in which you would like to browse the data in. To select a category, clock on the drop-down box and scroll up or down until you see what you want to explore. Simply click on the option you’d like. We then select what results we would like to view. Check or uncheck what columns we would like to show in the results.<\/p>\n         <p> Then, we will be able to rank the videos by Likes, Dislikes, Comment Count, Views, and Like-Dislike Ratio. By selecting one, the app will bring you to a page where you can search by keywords and sort by likes and alphabetical order of the title. You may also choose to see how many entries you view per page. To go to the next page, click on the numbers or next.<\/p>\n        \"\n      )\n    })\n    \n    output$Rankplot <- renderPlot(\n      graphdata %>%\n        ggplot(aes(y = fct_reorder(category_id_c,\n                                   eval(as.name(paste(input$Vars,\"_per_video\", sep=\"\")))\n                                   ),\n                   x = eval(as.name(paste(input$Vars, \"_per_video\", sep=\"\"))), \n                   fill = category_id_c)) +\n        geom_bar(stat = 'identity') +\n        labs(y = \"Category of Music\",\n             title = paste(\"Ranking of Category by\",input$Vars),\n             x = \"\"\n             )+\n        theme(legend.position = \"none\")\n    )\n\n    output$Boxplot <- renderPlot(\n      data_cleaned %>%\n        filter(category == input$Categoreis) %>%\n        mutate(category_c = as.character(category)) %>%\n        group_by(category_c) %>%\n        summarize(category_c, likes) %>%\n        ggplot(aes(y = reorder(category_c,likes,median), x=likes, fill = category_c)) +\n        geom_boxplot()+\n        labs(y = \"Category ID\",\n             x = \"Likes\",\n             title = \"Distribution by Category\")+\n        theme_minimal()+\n        xlim(0,100000)+\n        theme(legend.position = \"none\")\n    )\n    \n}\n\nshinyApp(ui = ui, server = server)\n\n\nShiny applications not supported in static R Markdown documents\n\n\n\n\n",
    "preview": "https://cdn.mos.cms.futurecdn.net/8gzcr6RpGStvZFA2qRt4v6.jpg",
    "last_modified": "2022-05-23T11:52:03-07:00",
    "input_file": {}
  },
  {
    "path": "posts/Spotify_Project/",
    "title": "Machine Learning Semester Project",
    "description": "We analyzed data from Spotify with the goal of predicting song popularity!",
    "author": [
      {
        "name": "Nicholas Di and Amy Xu",
        "url": {}
      }
    ],
    "date": "2020-05-01",
    "categories": [],
    "contents": "\nData Context\nWe selected the dataset “Top Spotify songs from 2010-2019 - BY YEAR”\nfrom Kaggle, which consists of the top songs by year in the world on\nSpotify, and the data is based on Billboard. The dataset contains 13\nvariables to be explored, including information about the songs such as\nthe song’s title, the song’s artist, the genre of the track, the year in\nwhich the song was in the Billboard rankings, its duration and\nacousticness. There are also variables describing the music, such as\nbeats per minute (which characterizes the tempo of the song), energy\n(the higher the value, the more energetic the song is), danceability\n(the higher the value, the easier it is to dance to this song), loudness\n(measured in dB), liveness (the higher the value, the more likely the\nsong is a live recording), valence (the higher the value, the more\npositive the mood is for the song), and speechiness (the higher the\nvalue, the more spoken words the song contains). The outcome variable in\nthis dataset is popularity, where the higher the value, the more popular\nthe song is.\nThe data were extracted from: http://organizeyourmusic.playlistmachinery.com/, and the\ndataset was constructed by Leonardo Henrique, updated in 2020. He was\ninterested in what we could know about the specific music genre based on\nthe popularity of the songs, and what elements would contribute to this\npopularity.\nResearch questions\nRegression: How can we predict the energy level of a song based on\nall other predictors? Classification: How can we predict whether the\nsong is amongst the most popular based on all other predictors?\n\n\n# Load data and required packages\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(ISLR)\nlibrary(splines)\nlibrary(caret)\nlibrary(stats)\nlibrary(lattice)\nlibrary(leaps)\nlibrary(gam)\ntop_spotify <- read_csv('https://www.dropbox.com/s/fi22whryueo4q85/top10s.csv?dl=1')\n\n\n\n\n\n# Any code to clean the data\ntop_spotify_new <- top_spotify %>% select(-artist,-'top genre',-title,-...1)\n#There seems to be an outlier \ntop_spotify_new <- filter(top_spotify_new, bpm > 1)\n\n\n\nInitial\ninvestigation 1: ignoring nonlinearity (for now)\nWe ordinary least squares (OLS) regression, forward and/or backward\nselection, and LASSO to build initial models for our quantitative\noutcome as a function of the predictors of interest.\nOLS Model\nFit the ordinary least squares (OLS) regression model:\n\n\nOLS <- lm(nrgy ~ year + acous + bpm + pop + dnce + live + spch + dur, data = top_spotify_new)\nsummary(OLS)\n\n\n\nCall:\nlm(formula = nrgy ~ year + acous + bpm + pop + dnce + live + \n    spch + dur, data = top_spotify_new)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-43.223  -8.030   1.092   8.540  31.239 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.347e+03  4.228e+02   5.552 4.26e-08 ***\nyear        -1.119e+00  2.097e-01  -5.337 1.34e-07 ***\nacous       -4.123e-01  2.611e-02 -15.790  < 2e-16 ***\nbpm         -3.427e-03  2.178e-02  -0.157  0.87504    \npop         -4.448e-02  3.713e-02  -1.198  0.23131    \ndnce         1.833e-03  4.190e-02   0.044  0.96511    \nlive         1.239e-01  4.012e-02   3.087  0.00212 ** \nspch         2.046e-01  6.916e-02   2.958  0.00322 ** \ndur         -7.281e-02  1.568e-02  -4.644 4.20e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.51 on 593 degrees of freedom\nMultiple R-squared:  0.402, Adjusted R-squared:  0.3939 \nF-statistic: 49.83 on 8 and 593 DF,  p-value: < 2.2e-16\n\nset.seed(253)\nOLS_cv <- train(\n    nrgy ~ year + acous + bpm + pop + dnce + live + spch + dur,\n    data = top_spotify_new,\n    method = \"lm\",\n    trControl = trainControl(method = \"cv\", number = 9),\n    na.action = na.omit)\n\n\n\nBackward Stepwise Selection\nModel\nFit the Backward Stepwise Selection model:\n\n\nfull_model <- lm(nrgy ~ ., data = top_spotify_new)\nsummary(full_model)\n\n\n\nCall:\nlm(formula = nrgy ~ ., data = top_spotify_new)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-28.7877  -6.2817   0.6035   6.8994  27.0338 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 812.704006 344.864487   2.357 0.018769 *  \nyear         -0.350636   0.171100  -2.049 0.040874 *  \nbpm          -0.004972   0.017149  -0.290 0.771957    \ndnce         -0.106738   0.037418  -2.853 0.004488 ** \ndB            4.479083   0.268874  16.659  < 2e-16 ***\nlive          0.103313   0.031586   3.271 0.001135 ** \nval           0.113503   0.022958   4.944 9.99e-07 ***\ndur          -0.017890   0.012827  -1.395 0.163629    \nacous        -0.289294   0.021547 -13.426  < 2e-16 ***\nspch          0.206303   0.055593   3.711 0.000226 ***\npop          -0.074613   0.029247  -2.551 0.010988 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.84 on 591 degrees of freedom\nMultiple R-squared:  0.6312,    Adjusted R-squared:  0.625 \nF-statistic: 101.2 on 10 and 591 DF,  p-value: < 2.2e-16\n\nset.seed(253)\nback_step_mod <- train(\n    nrgy ~ .,\n    data = top_spotify_new,\n    method = 'leapBackward',\n    tuneGrid = data.frame(nvmax = 1:10),\n    trControl = trainControl(method = 'cv',number = 9),\n    metric = 'MAE',\n    na.action = na.omit\n)\n\n\n\nForward Stepwise Selection\nModel\nFit the Forward Stepwise Selection model:\n\n\nset.seed(253)\nfor_step_mod <- train(\n    nrgy ~ .,\n    data = top_spotify_new,\n    method = 'leapForward',\n    tuneGrid = data.frame(nvmax = 1:10),\n    trControl = trainControl(method = 'cv',number = 9),\n    metric = 'MAE',\n    na.action = na.omit\n)\n\n\n\nLASSO Model\nFit the LASSO model:\n\n\nset.seed(253)\nlasso_mod <- train(\n    nrgy ~ .,\n    data = top_spotify_new,\n    method = \"glmnet\",\n    tuneGrid = data.frame(alpha = 1, lambda = seq(0, 10, length.out = 100)),\n    trControl = trainControl(method = \"cv\", number = 9, selectionFunction = 'oneSE'),\n    metric = \"MAE\",\n    na.action = na.omit)\n\n\n\nCompare performances\nof different models:\nEstimate test performance of the models from these different methods.\nReport and interpret (with units) these estimates along with a measure\nof uncertainty in the estimate (SD is most readily available from\ncaret).\nExamine OLS model outputs:\n\n\nsummary(OLS_cv)\n\n\n\nCall:\nlm(formula = .outcome ~ ., data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-43.223  -8.030   1.092   8.540  31.239 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.347e+03  4.228e+02   5.552 4.26e-08 ***\nyear        -1.119e+00  2.097e-01  -5.337 1.34e-07 ***\nacous       -4.123e-01  2.611e-02 -15.790  < 2e-16 ***\nbpm         -3.427e-03  2.178e-02  -0.157  0.87504    \npop         -4.448e-02  3.713e-02  -1.198  0.23131    \ndnce         1.833e-03  4.190e-02   0.044  0.96511    \nlive         1.239e-01  4.012e-02   3.087  0.00212 ** \nspch         2.046e-01  6.916e-02   2.958  0.00322 ** \ndur         -7.281e-02  1.568e-02  -4.644 4.20e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.51 on 593 degrees of freedom\nMultiple R-squared:  0.402, Adjusted R-squared:  0.3939 \nF-statistic: 49.83 on 8 and 593 DF,  p-value: < 2.2e-16\n\nOLS_cv$results\n\n\n  intercept     RMSE  Rsquared      MAE   RMSESD RsquaredSD   MAESD\n1      TRUE 12.62445 0.3880631 10.13206 1.140868  0.1381483 0.83748\n\nOn average, we’re off in top song energy predictions by about\n10.13206 points.\nResidual plot for OLS model:\n\n\nOLS_mod_output <- broom::augment(OLS, newdata = top_spotify_new)\n\nggplot(OLS_mod_output, aes(x = .fitted, y = .resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\")\n\n\n\n\nExamine Backward Stepwise Selection model output:\n\n\nsummary(back_step_mod)\n\n\nSubset selection object\n10 Variables  (and intercept)\n      Forced in Forced out\nyear      FALSE      FALSE\nbpm       FALSE      FALSE\ndnce      FALSE      FALSE\ndB        FALSE      FALSE\nlive      FALSE      FALSE\nval       FALSE      FALSE\ndur       FALSE      FALSE\nacous     FALSE      FALSE\nspch      FALSE      FALSE\npop       FALSE      FALSE\n1 subsets of each size up to 9\nSelection Algorithm: backward\n         year bpm dnce dB  live val dur acous spch pop\n1  ( 1 ) \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \" \"   \" \"  \" \"\n2  ( 1 ) \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \"*\"   \" \"  \" \"\n3  ( 1 ) \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \"*\"   \"*\"  \" \"\n4  ( 1 ) \" \"  \" \" \" \"  \"*\" \" \"  \"*\" \" \" \"*\"   \"*\"  \" \"\n5  ( 1 ) \" \"  \" \" \" \"  \"*\" \"*\"  \"*\" \" \" \"*\"   \"*\"  \" \"\n6  ( 1 ) \" \"  \" \" \"*\"  \"*\" \"*\"  \"*\" \" \" \"*\"   \"*\"  \" \"\n7  ( 1 ) \" \"  \" \" \"*\"  \"*\" \"*\"  \"*\" \" \" \"*\"   \"*\"  \"*\"\n8  ( 1 ) \"*\"  \" \" \"*\"  \"*\" \"*\"  \"*\" \" \" \"*\"   \"*\"  \"*\"\n9  ( 1 ) \"*\"  \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\" \"*\"   \"*\"  \"*\"\n\nplot(back_step_mod)\n\n\n\nback_step_mod$bestTune\n\n\n  nvmax\n9     9\n\nWe chose the model with 6 predictors. Although all 10 yields better\nmodel metrics, we believe that we will run into problems of\nover-fitting.\nOn average, we’re off in top song energy predictions by about 8.286\npercentage points, if we use the model with 6 predictors.\n\n\ncoef(back_step_mod$finalModel, id = 6)\n\n\n(Intercept)        dnce          dB        live         val \n 97.4672886  -0.1228588   4.5587752   0.1128596   0.1264183 \n      acous        spch \n -0.2930557   0.2006552 \n\nback_step_mod$results %>% filter(nvmax==6)\n\n\n  nvmax     RMSE  Rsquared      MAE    RMSESD RsquaredSD    MAESD\n1     6 10.18581 0.5910122 8.286481 0.9244708  0.1070956 0.825095\n\nback_step_mod_eq <- lm(nrgy ~ dnce + dB + live + val + acous + spch, data =top_spotify_new)\n\n\n\nResidual plot for Backward Step-wise Selection model:\n\n\nback_step_mod_out <- top_spotify_new %>%\n    mutate(\n        fitted = predict(back_step_mod_eq, newdata = top_spotify_new),\n        resid = nrgy - fitted\n    )\n\nggplot(back_step_mod_out, aes(x = fitted, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    theme_classic() +\n    labs(x = \"Fitted values\", y = \"Residuals\")\n\n\n\n\nFor Loop looking at all predictors in the Backward Stepwise Selection\nmodel:\n\n\npredictors <- setdiff(colnames(top_spotify_new), c(\"year\",\"bpm\",\"nrgy\",\"dur\",\"spch\"))\nfor (pred in predictors) {\n    p <- ggplot(back_step_mod_out, aes(x = .data[[pred]], y = resid)) +\n        geom_point() +\n        geom_smooth() +\n        geom_hline(yintercept = 0, color = \"red\") +\n        theme_classic() +\n        labs(x = pred, y = \"Residuals\")\n    print(p)\n}\n\n\n\n\nExamine Forward Stepwise Selection model output:\n\n\nsummary(for_step_mod)\n\n\nSubset selection object\n10 Variables  (and intercept)\n      Forced in Forced out\nyear      FALSE      FALSE\nbpm       FALSE      FALSE\ndnce      FALSE      FALSE\ndB        FALSE      FALSE\nlive      FALSE      FALSE\nval       FALSE      FALSE\ndur       FALSE      FALSE\nacous     FALSE      FALSE\nspch      FALSE      FALSE\npop       FALSE      FALSE\n1 subsets of each size up to 9\nSelection Algorithm: forward\n         year bpm dnce dB  live val dur acous spch pop\n1  ( 1 ) \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \" \"   \" \"  \" \"\n2  ( 1 ) \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \"*\"   \" \"  \" \"\n3  ( 1 ) \" \"  \" \" \" \"  \"*\" \" \"  \" \" \" \" \"*\"   \"*\"  \" \"\n4  ( 1 ) \" \"  \" \" \" \"  \"*\" \" \"  \"*\" \" \" \"*\"   \"*\"  \" \"\n5  ( 1 ) \" \"  \" \" \" \"  \"*\" \"*\"  \"*\" \" \" \"*\"   \"*\"  \" \"\n6  ( 1 ) \" \"  \" \" \"*\"  \"*\" \"*\"  \"*\" \" \" \"*\"   \"*\"  \" \"\n7  ( 1 ) \" \"  \" \" \"*\"  \"*\" \"*\"  \"*\" \" \" \"*\"   \"*\"  \"*\"\n8  ( 1 ) \"*\"  \" \" \"*\"  \"*\" \"*\"  \"*\" \" \" \"*\"   \"*\"  \"*\"\n9  ( 1 ) \"*\"  \" \" \"*\"  \"*\" \"*\"  \"*\" \"*\" \"*\"   \"*\"  \"*\"\n\nplot(for_step_mod)\n\n\n\nfor_step_mod$results\n\n\n   nvmax      RMSE  Rsquared      MAE    RMSESD RsquaredSD     MAESD\n1      1 11.993192 0.4404595 9.440092 1.1663410 0.08326330 0.7602086\n2      2 10.477550 0.5683678 8.533998 0.6892741 0.09392739 0.6832649\n3      3 10.421451 0.5699856 8.442041 0.8481219 0.10845490 0.7918324\n4      4 10.333804 0.5765861 8.412541 0.8391433 0.11095779 0.7986408\n5      5 10.260625 0.5846211 8.383712 0.8495003 0.11238655 0.7669223\n6      6 10.142928 0.5941810 8.277152 0.8950607 0.10739226 0.8186073\n7      7  9.950075 0.6082421 8.067531 0.9987578 0.11136222 0.8886527\n8      8  9.940663 0.6092391 8.072114 0.9905555 0.10712761 0.9066449\n9      9  9.902507 0.6120420 8.049632 0.9827727 0.10630862 0.9021970\n10    10  9.915936 0.6110377 8.062302 0.9829506 0.10702524 0.9087888\n\nUsing Forward selection, we chose the model with 5 predictors. The\nfive predictors being acous, dB, live, spch, and val.\nOn average, we’re off in top song energy predictions by about\n8.383712 percentage points.\n\n\ncoef(for_step_mod$finalModel, id = 5)\n\n\n(Intercept)          dB        live         val       acous \n91.50592402  4.65576857  0.11831750  0.09041016 -0.28031999 \n       spch \n 0.22151861 \n\nfor_step_mod$results %>% filter(nvmax==5)\n\n\n  nvmax     RMSE  Rsquared      MAE    RMSESD RsquaredSD     MAESD\n1     5 10.26063 0.5846211 8.383712 0.8495003  0.1123866 0.7669223\n\nfor_step_mod_eq <- lm(nrgy ~ acous + dB + val + spch + live, data =top_spotify_new)\n\n\n\nResidual plot for Forward Stepwise Selection model:\n\n\nfor_step_mod_out <- top_spotify_new %>%\n    mutate(\n        fitted = predict(for_step_mod_eq, newdata = top_spotify_new),\n        resid = nrgy - fitted\n    )\n\nggplot(for_step_mod_out, aes(x = fitted, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    theme_classic() +\n    labs(x = \"Fitted values\", y = \"Residuals\")\n\n\n\n\nFor Loop looking at all predictors in the Forward Stepwise Selection\nmodel:\n\n\npredictors <- setdiff(colnames(top_spotify_new), c(\"year\",\"bpm\",\"nrgy\",\"dur\",\"pop\", \"dnce\"))\nfor (pred in predictors) {\n    p <- ggplot(for_step_mod_out, aes(x = .data[[pred]], y = resid)) +\n        geom_point() +\n        geom_smooth() +\n        geom_hline(yintercept = 0, color = \"red\") +\n        theme_classic() +\n        labs(x = pred, y = \"Residuals\")\n    print(p)\n}\n\n\n\n\nExamine LASSO model output:\n\n\nplot(lasso_mod$finalModel, xvar = \"lambda\", label = TRUE, col = rainbow(20))\n\n\n\nlasso_mod$bestTune\n\n\n   alpha   lambda\n11     1 1.010101\n\n# lasso_mod$results\nrownames(lasso_mod$finalModel$beta)[c(4,8)]\n\n\n[1] \"dB\"    \"acous\"\n\nWe chose a lambda value of 1.010101, dB and acous seem to be two of\nthe strongest/persistent predictors when it comes to energy-level.\n\n\ncoef(lasso_mod$finalModel, 1.010101)\n\n\n11 x 1 sparse Matrix of class \"dgCMatrix\"\n                      s1\n(Intercept) 427.22094252\nyear         -0.16551620\nbpm           .         \ndnce          .         \ndB            4.25384058\nlive          0.05257947\nval           0.06575686\ndur           .         \nacous        -0.25154488\nspch          0.10397394\npop          -0.02164891\n\nlasso_mod$results[11,]\n\n\n   alpha   lambda     RMSE Rsquared     MAE    RMSESD RsquaredSD\n11     1 1.010101 10.17634 0.597547 8.32769 0.8552498  0.1057273\n       MAESD\n11 0.7932597\n\nOn average, we’re off in top song energy predictions by about 8.32769\npercentage points using LASSO with a lambda of 1.010101.\nResidual plot for LASSO model:\n\n\nlasso_mod_out <- top_spotify_new %>%\n    mutate(\n        fitted = predict(lasso_mod, newdata = top_spotify_new),\n        resid = nrgy - fitted)\nggplot(lasso_mod_out, aes(x = fitted, y = resid)) +\n    geom_point() +\n    geom_smooth() +\n    geom_hline(yintercept = 0, color = \"red\") +\n    theme_classic() +\n    labs(x = \"Fitted values\", y = \"Residuals\")\n\n\n\n\nThere does not seem to be any noticable patterns of over and\nunderpredicting here!\nFor Loop for LASSO model:\n\n\npredictors <- setdiff(colnames(top_spotify_new), \"Top Spotify\")\nfor (pred in predictors) {\n    p <- ggplot(lasso_mod_out, aes(x = .data[[pred]], y = resid)) +\n        geom_point() +\n        geom_smooth() +\n        geom_hline(yintercept = 0, color = \"red\") +\n        theme_classic() +\n        labs(x = pred, y = \"Residuals\")\n    print(p)\n}\n\n\n\n\nCompare estimated test performance across methods. Which method(s)\nmight you prefer?\nModel\nTraining MAE\nMAESD\nOLS Model\n10.13206\n0.83748\nBackward\n8.286481\n0.825095\nForward\n8.383712\n0.7669223\nLASSO\n8.32769\n0.7932597\nComparing the four models, LASSO and Backward Stepwise Selection\nmodels seem to be yielding the best results as the predictions for top\nsong energy level are closest to the test value.\nCompare insights from variable importance analyses from the different\nmethods (stepwise and LASSO, but not OLS). Are there variables for which\nthe methods reach consensus? What insights are expected? Surprising?\nAcross all models, the “top” 3 predictors for song energy level are\nacous (Acousticness- the higher the value the more acoustic the song\nis), dB(Loudness, the higher the value, the louder the song), and\nval(Valence, the higher the value, the more positive mood for the song).\nThis is mostly consistent with our expectation, as when the song is\nlouder, and more positive, the song has a higher energy level. It is a\nbit surprising that when a song is more acoustic, it is less\nenergetic.\nNote that if some (but not all) of the indicator terms for a\ncategorical predictor are selected in the final models, the whole\npredictor should be treated as selected.\nInvestigation 2:\nAccounting for nonlinearity\nUpdate your stepwise selection model(s) and LASSO model to use\nnatural splines for the quantitative predictors.\nYou’ll need to update the model formula from y ~ . to\nsomething like\ny ~ cat_var1 + ns(quant_var1, df) + ....\nIt’s recommended to use few knots (e.g., 2 knots = 3 degrees of\nfreedom).\nNote that ns(x,3) replaces x with 3\ntransformations of x. Keep this in mind when setting\nnvmax in stepwise selection.\n\n\nggplot(top_spotify_new, aes(x = val, y = nrgy)) +\n    geom_point(alpha = 0.25) +\n    geom_smooth(color = \"blue\", se = FALSE) +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\nggplot(top_spotify_new, aes(x = dB, y = nrgy)) +\n    geom_point(alpha = 0.25) +\n    geom_smooth(color = \"blue\", se = FALSE) +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\nggplot(top_spotify_new, aes(x = acous, y = nrgy)) +\n    geom_point(alpha = 0.25) +\n    geom_smooth(color = \"blue\", se = FALSE) +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\nggplot(top_spotify_new, aes(x = year, y = nrgy)) +\n    geom_point(alpha = 0.25) +\n    geom_smooth(color = \"blue\", se = FALSE) +\n    geom_smooth(method = \"lm\", color = \"red\", se = FALSE)\n\n\n\n\nBackward\nStepwise Selection model with natural splines\nUpdate the Backward Stepwise Selection model to use natural splines\nfor the quantitative predictors:\n\n\nset.seed(253)\nback_spline_mod <- train(\n    nrgy ~ ns(acous, 3) + ns(pop, 3) + ns(dnce, 3) + ns(live, 3) + ns(dB, 3) + ns(val, 3),\n    data = top_spotify_new,\n    method = \"leapBackward\",\n    trControl = trainControl(method = \"cv\", number = 9, selectionFunction = \"oneSE\"),\n    metric = \"MAE\",\n    na.action = na.omit\n)\n\n\n\nForward\nStepwise Selection model with natural splines\nUpdate the Forward Stepwise Selection model to use natural splines\nfor the quantitative predictors:\n\n\nset.seed(253)\nfor_spline_mod <- train(\n    nrgy ~ ns(year, 3) + ns(acous, 3) + ns(bpm, 3) + ns(pop, 3) + ns(dnce, 3) + ns(live, 3) + ns(spch, 3) + ns(dur, 3),\n    data = top_spotify_new,\n    method = \"leapForward\",\n    trControl = trainControl(method = \"cv\", number = 9, selectionFunction = \"oneSE\"),\n    metric = \"MAE\",\n    na.action = na.omit\n)\n\n\n\nLASSO model with natural\nsplines\nUpdate the LASSO model to use natural splines for the quantitative\npredictors:\n\n\nset.seed(253)\nLASSO_spline_mod <- train(\n    nrgy ~ ns(year, 3) + ns(acous, 3) + ns(bpm, 3) + ns(pop, 3) + ns(dnce, 3) + ns(live, 3) + ns(spch, 3) + ns(dur, 3),\n    data = top_spotify_new,\n    method = \"glmnet\",\n    tuneGrid = data.frame(alpha = 1, lambda = seq(0, 10, length.out = 100)),\n    trControl = trainControl(method = \"cv\", number = 9, selectionFunction = \"oneSE\"),\n    metric = \"MAE\",\n    na.action = na.omit\n)\n\n\n\nCompare\ninsights from variable importance analyses\nCompare insights from variable importance analyses here and the\ncorresponding results from Investigation 1. Now after having accounted\nfor nonlinearity, have the most relevant predictors changed?\nNote that if some (but not all) of the spline terms are selected in\nthe final models, the whole predictor should be treated as\nselected.\nExamine Backward Stepwise Selection model with natural splines\noutput:\n\n\nsummary(back_spline_mod)\n\n\nSubset selection object\n18 Variables  (and intercept)\n              Forced in Forced out\nns(acous, 3)1     FALSE      FALSE\nns(acous, 3)2     FALSE      FALSE\nns(acous, 3)3     FALSE      FALSE\nns(pop, 3)1       FALSE      FALSE\nns(pop, 3)2       FALSE      FALSE\nns(pop, 3)3       FALSE      FALSE\nns(dnce, 3)1      FALSE      FALSE\nns(dnce, 3)2      FALSE      FALSE\nns(dnce, 3)3      FALSE      FALSE\nns(live, 3)1      FALSE      FALSE\nns(live, 3)2      FALSE      FALSE\nns(live, 3)3      FALSE      FALSE\nns(dB, 3)1        FALSE      FALSE\nns(dB, 3)2        FALSE      FALSE\nns(dB, 3)3        FALSE      FALSE\nns(val, 3)1       FALSE      FALSE\nns(val, 3)2       FALSE      FALSE\nns(val, 3)3       FALSE      FALSE\n1 subsets of each size up to 4\nSelection Algorithm: backward\n         ns(acous, 3)1 ns(acous, 3)2 ns(acous, 3)3 ns(pop, 3)1\n1  ( 1 ) \" \"           \" \"           \" \"           \" \"        \n2  ( 1 ) \" \"           \" \"           \"*\"           \" \"        \n3  ( 1 ) \" \"           \"*\"           \"*\"           \" \"        \n4  ( 1 ) \" \"           \"*\"           \"*\"           \" \"        \n         ns(pop, 3)2 ns(pop, 3)3 ns(dnce, 3)1 ns(dnce, 3)2\n1  ( 1 ) \" \"         \" \"         \" \"          \" \"         \n2  ( 1 ) \" \"         \" \"         \" \"          \" \"         \n3  ( 1 ) \" \"         \" \"         \" \"          \" \"         \n4  ( 1 ) \" \"         \" \"         \" \"          \" \"         \n         ns(dnce, 3)3 ns(live, 3)1 ns(live, 3)2 ns(live, 3)3\n1  ( 1 ) \" \"          \" \"          \" \"          \" \"         \n2  ( 1 ) \" \"          \" \"          \" \"          \" \"         \n3  ( 1 ) \" \"          \" \"          \" \"          \" \"         \n4  ( 1 ) \" \"          \" \"          \" \"          \" \"         \n         ns(dB, 3)1 ns(dB, 3)2 ns(dB, 3)3 ns(val, 3)1 ns(val, 3)2\n1  ( 1 ) \" \"        \" \"        \"*\"        \" \"         \" \"        \n2  ( 1 ) \" \"        \" \"        \"*\"        \" \"         \" \"        \n3  ( 1 ) \" \"        \" \"        \"*\"        \" \"         \" \"        \n4  ( 1 ) \"*\"        \" \"        \"*\"        \" \"         \" \"        \n         ns(val, 3)3\n1  ( 1 ) \" \"        \n2  ( 1 ) \" \"        \n3  ( 1 ) \" \"        \n4  ( 1 ) \" \"        \n\nplot(back_spline_mod)\n\n\n\nback_spline_mod$bestTune\n\n\n  nvmax\n3     4\n\nback_spline_mod$results\n\n\n  nvmax     RMSE  Rsquared       MAE    RMSESD RsquaredSD     MAESD\n1     2 12.94073 0.3520225 10.551403 1.0723596 0.09809830 0.7221742\n2     3 11.21314 0.5103530  9.152245 0.9208166 0.07104034 0.7258275\n3     4 10.28440 0.5900269  8.392090 0.8083434 0.09138549 0.7327469\n\nAccording to the Backward Stepwise Selection model with natural\nsplines, the top predictors for song energy level are acous and dB.\nExamine Forward Stepwise Selection model output:\n\n\nsummary(for_spline_mod)\n\n\nSubset selection object\n24 Variables  (and intercept)\n              Forced in Forced out\nns(year, 3)1      FALSE      FALSE\nns(year, 3)2      FALSE      FALSE\nns(year, 3)3      FALSE      FALSE\nns(acous, 3)1     FALSE      FALSE\nns(acous, 3)2     FALSE      FALSE\nns(acous, 3)3     FALSE      FALSE\nns(bpm, 3)1       FALSE      FALSE\nns(bpm, 3)2       FALSE      FALSE\nns(bpm, 3)3       FALSE      FALSE\nns(pop, 3)1       FALSE      FALSE\nns(pop, 3)2       FALSE      FALSE\nns(pop, 3)3       FALSE      FALSE\nns(dnce, 3)1      FALSE      FALSE\nns(dnce, 3)2      FALSE      FALSE\nns(dnce, 3)3      FALSE      FALSE\nns(live, 3)1      FALSE      FALSE\nns(live, 3)2      FALSE      FALSE\nns(live, 3)3      FALSE      FALSE\nns(spch, 3)1      FALSE      FALSE\nns(spch, 3)2      FALSE      FALSE\nns(spch, 3)3      FALSE      FALSE\nns(dur, 3)1       FALSE      FALSE\nns(dur, 3)2       FALSE      FALSE\nns(dur, 3)3       FALSE      FALSE\n1 subsets of each size up to 3\nSelection Algorithm: forward\n         ns(year, 3)1 ns(year, 3)2 ns(year, 3)3 ns(acous, 3)1\n1  ( 1 ) \" \"          \" \"          \" \"          \" \"          \n2  ( 1 ) \" \"          \" \"          \" \"          \" \"          \n3  ( 1 ) \" \"          \" \"          \" \"          \" \"          \n         ns(acous, 3)2 ns(acous, 3)3 ns(bpm, 3)1 ns(bpm, 3)2\n1  ( 1 ) \" \"           \"*\"           \" \"         \" \"        \n2  ( 1 ) \"*\"           \"*\"           \" \"         \" \"        \n3  ( 1 ) \"*\"           \"*\"           \" \"         \" \"        \n         ns(bpm, 3)3 ns(pop, 3)1 ns(pop, 3)2 ns(pop, 3)3 ns(dnce, 3)1\n1  ( 1 ) \" \"         \" \"         \" \"         \" \"         \" \"         \n2  ( 1 ) \" \"         \" \"         \" \"         \" \"         \" \"         \n3  ( 1 ) \" \"         \" \"         \" \"         \" \"         \" \"         \n         ns(dnce, 3)2 ns(dnce, 3)3 ns(live, 3)1 ns(live, 3)2\n1  ( 1 ) \" \"          \" \"          \" \"          \" \"         \n2  ( 1 ) \" \"          \" \"          \" \"          \" \"         \n3  ( 1 ) \" \"          \" \"          \" \"          \" \"         \n         ns(live, 3)3 ns(spch, 3)1 ns(spch, 3)2 ns(spch, 3)3\n1  ( 1 ) \" \"          \" \"          \" \"          \" \"         \n2  ( 1 ) \" \"          \" \"          \" \"          \" \"         \n3  ( 1 ) \" \"          \" \"          \"*\"          \" \"         \n         ns(dur, 3)1 ns(dur, 3)2 ns(dur, 3)3\n1  ( 1 ) \" \"         \" \"         \" \"        \n2  ( 1 ) \" \"         \" \"         \" \"        \n3  ( 1 ) \" \"         \" \"         \" \"        \n\nplot(for_spline_mod)\n\n\n\nfor_spline_mod$bestTune\n\n\n  nvmax\n2     3\n\nfor_spline_mod$results\n\n\n  nvmax     RMSE  Rsquared      MAE    RMSESD RsquaredSD     MAESD\n1     2 12.86781 0.3498257 10.55154 0.9235936 0.10765745 0.6993457\n2     3 12.92971 0.3449085 10.51615 0.9716964 0.09693563 0.6348611\n3     4 12.69644 0.3685762 10.30346 0.8366573 0.10280846 0.6553263\n\nAccording to the Forward Stepwise Selection model with natural\nsplines, the top predictor for song energy level is acous.\nExamine LASSO model with natural splines output:\n\n\nsummary(LASSO_spline_mod)\n\n\n            Length Class      Mode     \na0            72   -none-     numeric  \nbeta        1728   dgCMatrix  S4       \ndf            72   -none-     numeric  \ndim            2   -none-     numeric  \nlambda        72   -none-     numeric  \ndev.ratio     72   -none-     numeric  \nnulldev        1   -none-     numeric  \nnpasses        1   -none-     numeric  \njerr           1   -none-     numeric  \noffset         1   -none-     logical  \ncall           5   -none-     call     \nnobs           1   -none-     numeric  \nlambdaOpt      1   -none-     numeric  \nxNames        24   -none-     character\nproblemType    1   -none-     character\ntuneValue      2   data.frame list     \nobsLevels      1   -none-     logical  \nparam          0   -none-     list     \n\nplot(LASSO_spline_mod)\n\n\n\nLASSO_spline_mod$bestTune\n\n\n  alpha    lambda\n6     1 0.5050505\n\n# LASSO_spline_mod$results\n\n\n\nThe lambda value provided by the LASSO model with splines is\n0.5050505.\nGAM with LOESS terms\nFit a GAM using LOESS terms using the set of variables deemed to be\nmost relevant based on your investigations so far.\nHow does test performance of the GAM compare to other models you\nexplored?\nDo you gain any insights from the GAM output plots for each\npredictor?\n\n\nset.seed(253)\ngam_mod <- train(\n    nrgy ~ acous + val + dB,\n    data = top_spotify_new,\n    method = \"gamLoess\",\n    tuneGrid = data.frame(degree = 1, span = seq(0.1, 0.9, by = 0.1)),\n    trControl = trainControl(method = \"cv\", number = 9, selectionFunction = \"best\"),\n    metric = \"MAE\",\n    na.action = na.omit\n)\n\n\n\nExamine GAM with LOESS output:\n\n\ngam_mod$results[3,]\n\n\n  degree span     RMSE  Rsquared      MAE   RMSESD RsquaredSD\n3      1  0.3 10.20914 0.5906928 8.252745 0.892152  0.1020878\n      MAESD\n3 0.8103724\n\n\n\nplot(gam_mod)\n\n\n\n#Metrics for the best model \ngam_mod$results %>%\n    filter(span==gam_mod$bestTune$span)\n\n\n  degree span     RMSE  Rsquared      MAE   RMSESD RsquaredSD\n1      1  0.3 10.20914 0.5906928 8.252745 0.892152  0.1020878\n      MAESD\n1 0.8103724\n\n#Graphing Each Predictor \npar(mfrow = c(3,4)) # Sets up a grid of plots\nplot(gam_mod$finalModel, se = TRUE) # Dashed lines are +/- 2 SEs\n\n\n\n\nGAM with a span of 0.3 offers a MAE of 8.252745, indicating that we\nour predictions for top song energy level would be off by 8.368585\npercentage points in this case. This result is actually better than all\nfour previous models fitted in the first section.\nSummarize investigations\nDecide on an overall best model based on your investigations so far.\nTo do this, make clear your analysis goals. Predictive accuracy?\nInterpretability? A combination of both?\nOverall, based on the output given by all of the models we fitted\nabove, it seems that a GAM with LOESS model achieves the lowest MAE for\nour dataset. For our analysis, since we want to correctly predict the\nenergy level of a popular song, we care about the predictive accuracy of\nthe model. We are also interested in knowing what contributes to an\nenergetic song, thus interpretability is also essential for the model.\nTherefore splines doesn’t seem the most straightforward choice for us,\nwhereas either GAM with LOESS or LASSO seems like a better option.\nSocietal impact\nAre there any harms that may come from your analyses and/or how the\ndata were collected? What cautions do you want to keep in mind when\ncommunicating your work?\nOur models takes a harmless look at the deciding elements of an\nenergetic song, as under the environment of a global pandemic where\nsocial interactions are limited, it is important to look for means to\nmaintain a positive mood, and it seems that listening to uplifting pop\nmusic is a favorable way to do so. Given our dataset, though, since the\nsource is Spotify and Billboard, our scope of pop music is limited and\nmay result in a certain pattern in our predictions. We want to caution\nthat good music choice should by no means be limited, and it should\nalways be optimal to listen to whatever one’s heart desires.\nClassification analysis\n(Methods)\nWe used logistic regression and random forest for building\nclassification models.\nLogistic Regression\nWe converted the predictor “pop” to categorical, assigning the\nobservations with value above 75 to be top songs.\n\n\ntop_spotify_new$IsPop <- \"NO\"\ntop_spotify_new$IsPop[top_spotify_new$pop >= 75] <- \"YES\"\ntable(top_spotify_new$IsPop)\ntable(top_spotify_new$pop)\ntop_spotify_new$IsPop <- factor(top_spotify_new$IsPop)\n\n\n\nWe then fit the logistic regression model predicting whether a given\nsong is a popular song with all other predictors. We selected the\nmetrics Accuracy so that the model we fit would prioritize making the\nmost accurate predictions.\n\n\nset.seed(253)\nlogistic_mod <- train(\n    IsPop ~ .-pop,\n    data = top_spotify_new,\n    method = \"glm\",\n    family = \"binomial\",\n    trControl = trainControl(method = \"cv\", number = 10),\n    metric = \"Accuracy\",\n    na.action = na.omit\n)\nsummary(logistic_mod$results)\n\n\n  parameter            Accuracy          Kappa       \n Length:1           Min.   :0.7124   Min.   :0.2109  \n Class :character   1st Qu.:0.7124   1st Qu.:0.2109  \n Mode  :character   Median :0.7124   Median :0.2109  \n                    Mean   :0.7124   Mean   :0.2109  \n                    3rd Qu.:0.7124   3rd Qu.:0.2109  \n                    Max.   :0.7124   Max.   :0.2109  \n   AccuracySD         KappaSD       \n Min.   :0.02915   Min.   :0.07924  \n 1st Qu.:0.02915   1st Qu.:0.07924  \n Median :0.02915   Median :0.07924  \n Mean   :0.02915   Mean   :0.07924  \n 3rd Qu.:0.02915   3rd Qu.:0.07924  \n Max.   :0.02915   Max.   :0.07924  \n\ncoefficients(logistic_mod$finalModel) %>% exp()\n\n\n  (Intercept)          year           bpm          nrgy          dnce \n1.508016e-192  1.246311e+00  1.000621e+00  9.717299e-01  1.007890e+00 \n           dB          live           val           dur         acous \n 1.147383e+00  9.915256e-01  1.006670e+00  9.968091e-01  1.001887e+00 \n         spch \n 9.881283e-01 \n\nWe also fit the LASSO logistic regression, gaining insight about\nvariable importance.\n\n\ntwoClassSummaryCustom <- function (data, lev = NULL, model = NULL) {\n    if (length(lev) > 2) {\n        stop(paste(\"Your outcome has\", length(lev), \"levels. The twoClassSummary() function isn't appropriate.\"))\n    }\n    caret:::requireNamespaceQuietStop(\"pROC\")\n    if (!all(levels(data[, \"pred\"]) == lev)) {\n        stop(\"levels of observed and predicted data do not match\")\n    }\n    rocObject <- try(pROC::roc(data$obs, data[, lev[1]], direction = \">\", \n        quiet = TRUE), silent = TRUE)\n    rocAUC <- if (inherits(rocObject, \"try-error\")) \n        NA\n    else rocObject$auc\n    out <- c(rocAUC, sensitivity(data[, \"pred\"], data[, \"obs\"], \n        lev[1]), specificity(data[, \"pred\"], data[, \"obs\"], lev[2]))\n    out2 <- postResample(data[, \"pred\"], data[, \"obs\"])\n    out <- c(out, out2[1])\n    names(out) <- c(\"AUC\", \"Sens\", \"Spec\", \"Accuracy\")\n    out\n}\nset.seed(253)\nlasso_logistic_mod <- train(\n    IsPop ~ .-pop,\n    data = top_spotify_new,\n    method = \"glmnet\",\n    family = \"binomial\",\n    tuneGrid = data.frame(alpha = 1, lambda = seq(0, 1, length.out = 100)),\n    trControl = trainControl(method = \"cv\", number = 10, selectionFunction = \"oneSE\", classProbs = TRUE, summaryFunction = twoClassSummaryCustom),\n    metric = \"AUC\",\n    na.action = na.omit\n)\n\nplot(lasso_logistic_mod)\n\n\n\n\n\n\nlasso_logistic_mod$bestTune\nlasso_logistic_mod$results\nlasso_logistic_mod$results %>%\n    filter(lambda==lasso_logistic_mod$bestTune$lambda)\nplot(lasso_logistic_mod$finalModel, xvar = \"lambda\", label = TRUE, col = rainbow(20), ylim = c(-0.5,7))\n\nrownames(lasso_logistic_mod$finalModel$beta)[c(5,3,1)]\n\n\n\nTrees and Random Forest\nWe fit trees and random forest to make predictions as well, using all\nother predictors to predict whether an observation is a popular song or\nnot. The metrics we selected is Accuracy, so that the model would\nprioritize making accurate predictions.\n\n\nset.seed(253)\ntree_mod <- train(\n    IsPop ~ .-pop,\n    data = top_spotify_new,\n    method = \"rpart\",\n    tuneGrid = data.frame(cp = seq(0, 0.5, length.out = 50)),\n    trControl = trainControl(method = \"cv\", number = 10, selectionFunction = \"oneSE\"),\n    metric = \"Accuracy\",\n    na.action = na.omit\n)\n\nplot(tree_mod)\n\n\n\ntree_mod$results %>%\n    filter(cp==tree_mod$bestTune$cp)\n\n\n         cp  Accuracy    Kappa AccuracySD KappaSD\n1 0.1020408 0.7143012 0.181339 0.03461561 0.13422\n\n\n\nrf_mod <- train(\n    IsPop ~ .-pop,\n    data = top_spotify_new,\n    method = \"rf\",\n    tuneGrid = data.frame(mtry = c(2,3,4,5,6,7,8)),\n    trControl = trainControl(method = \"oob\", selectionFunction = \"best\"),\n    metric = \"Accuracy\",\n    ntree = 750, # To force fitting 1000 trees (can help with stability of results)\n    na.action = na.omit\n)\nplot(rf_mod)\n\n\n\nrf_mod$results\n\n\n   Accuracy     Kappa mtry\n1 0.7524917 0.3347524    2\n2 0.7425249 0.3147939    3\n3 0.7342193 0.3007419    4\n4 0.7392027 0.3082283    5\n5 0.7342193 0.2961637    6\n6 0.7358804 0.2947911    7\n7 0.7375415 0.3026788    8\n\nrf_mod$finalModel\n\n\n\nCall:\n randomForest(x = x, y = y, ntree = 750, mtry = min(param$mtry,      ncol(x))) \n               Type of random forest: classification\n                     Number of trees: 750\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 26.08%\nConfusion matrix:\n     NO YES class.error\nNO  384  29  0.07021792\nYES 128  61  0.67724868\n\nOur model is better at identifying songs that are not popular. In our\ncontext, it helps us avoid bad songs, which is preferable than the more\nlenient alternative which is more likely to falsely categorize a song as\npopular.\n\n\nvar_imp_rf <- randomForest::importance(rf_mod$finalModel)\n\n# Sort by importance with dplyr's arrange()\nvar_imp_rf <- data.frame(\n        predictor = rownames(var_imp_rf),\n        MeanDecreaseGini = var_imp_rf[,\"MeanDecreaseGini\"]\n    ) %>%\n    arrange(desc(MeanDecreaseGini))\n\n# Top 10\nhead(var_imp_rf, 10)\n\n\n      predictor MeanDecreaseGini\nyear       year         34.01757\nval         val         29.91566\ndur         dur         29.62221\nnrgy       nrgy         29.08262\nbpm         bpm         27.71691\ndnce       dnce         26.28274\nacous     acous         24.00443\nlive       live         23.57061\nspch       spch         18.39002\ndB           dB         15.18356\n\nIt seems that the most important predictor, given contributions to\ndecreasing the Gini index, is year, which is pretty interesting. This\ntells us that knowing what year the song is released would offer us much\ninsight into whether the song is likely to be popular.\nClassification\nAnalysis (Results- Variable Importance)\nFor our logistic regression model, we utilized a LASSO logistic\nregression to gain insight on variable importance. The results\ndemonstrate that dnce, and bpm are the most important variables for\npredicting the popularity of a song. These results are sensible because\nit is plausible that more upbeat songs that you can dance to will be\nvaluable traits that may lead a song to be more popular.\nIn our random forest model, it shows that year is by far the most\nimportant variable for predicting song popularity, which also\ncorresponds to the most important variable as determined by the variable\nimportance measure of a single decision tree. This is because it lowers\nto Gini index the most on average for all the trees. Year is not very\ninsightful, though, because it is possible that the popular songs\nfeatured in this dataset came more from particular years than others. It\ndoesn’t really help us predict the future popularity of a song. More\ninterestingly, the energy displayed by a song has the second most\nmeaningful mean decrease in the Gini index. Again, this is sensible\nbecause the goal of a song often times is to portray energy to its\nlistener, so it makes sense that songs that accomplish this goal would\nbe more popular. 22\nClassification analysis\n(Summary)\nCompare models\nCompare the 2 different classification models tried in light of\nevaluation metrics, variable importance, and data context:\nWe have compared a logistic regression and a decision tree model. To\ncomplement the models, we have ran a LASSO logistic regression and a\nrandom forest. We are trying to predict whether a song will be\nrelatively popular. We have created our own binary variable with a\nthreshold of > 75 in pop to be considered popular (IsPop = YES). In\nall models, the most important variable seemed to be year. In this\ncontext, songs released in a certain year seem to be the most popular.\nOther important variables were energy levels and dance-ibility, both of\nwhich intuitively make sense as they would be more commonly enjoyed\namong music listeners.\nEvaluation metrics\nDisplay evaluation metrics for different models in a clean, organized\nway. This display should include both the estimated metric as well as\nits standard deviation. (This won’t be available from OOB error\nestimation. If using OOB, don’t worry about reporting the SD.):\nLogistic Regression Accuracy: 0.7124414 Logistic Regression Accuracy\nSD: 0.0291491\nLasso Logistic Regression Accuracy: 0.6860489 Lasso Logistic\nRegression Accuracy SD: 0.003961554 Lasso Logistic Regression AUC:\n0.6715804 Lasso Logistic Regression AUC SD: 0.07519223\nDecision Tree Accuracy: 0.7143012 Decision Tree Accuracy SD:\n0.03461561\nRandom Forest Accuracy: 0.7524917 Random Forest Confusion Matrix:\nPREDICTED\n  NO YES class.error\nNO 380 33 0.07990315 YES 122 67 0.64550265\nNIR: (413)/(413+189) = 68.6% The NIR is calculated using the whole\ntraining set.\nBroadly summarize conclusions from looking at these evaluation\nmetrics and their measures of uncertainty:\nWe can see that the model that gives us the least amount of variance\nis lasso logistic regression. However, we note that we are not trying to\nbuild the model with the smallest variance, as the variance is just a\nway to look at the uncertainty of in estimation of test performance,\nwhich is not so high when using lasso logistic regression. Random Forest\nseems to have the highest accuracy. With an OOB estimate error rate of\n25.75%, this is reflective of our accuracy.\nOverall most preferable\nmodel\nThe overall most preferable model would be our random forest model.\nThe accuracy in this model far outweighs all other models at an accuracy\nof 75.25% Random forests also provide out of bag error estimations,\nwhich give us an accountable measurement of error in our model.\nInterpretion of evaluation metric(s) for the final model in context.\nDoes the model show an acceptable amount of error:\nWith an overall accuracy of 75.2%, and a NIR of 68.6%, we believe\nthis model shows an acceptable amount of error.\nIf using OOB error estimation, display the test (OOB) confusion\nmatrix, and use it to interpret the strengths and weaknesses of the\nfinal model:\nWe can see that we have a sensitivity of (67)/(67+112) = 37.43% and a\nspecificity of (380)/(380+33) = 92.01%. Our model is good at correctly\npredicting songs that won’t be as popular. However, our model is bad at\ncorrectly predicting songs that won’t be popular.\n\n\nPopularSongs <- top_spotify_new[top_spotify_new$pop >= 75, ]\ntable(PopularSongs$year)\n\n\n\n2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 \n   9   10   10   16   12   24   23   25   32   28 \n\ntable(top_spotify_new$year)\n\n\n\n2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 \n  51   53   35   71   58   95   79   65   64   31 \n\nWe can see that although years are fairly balanced, the years when\nlooking at popular songs seem to be skewed towards later years. This\nmeans makes sense as the more “popular” songs seem to be the more recent\nones.\n\n\n\n",
    "preview": "https://storage.googleapis.com/pr-newsroom-wp/1/2018/11/Spotify_Logo_CMYK_Green.png",
    "last_modified": "2022-05-23T14:36:38-07:00",
    "input_file": {}
  }
]
